{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 71321,
          "databundleVersionId": 8065648,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polinak1r/Document-Ranking-Information-Retrieval/blob/main/document_ranking_information_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Notebook Outline: Document Ranking & Information Retrieval\n",
        "\n",
        "1. **Kaggle Setup and Data Download**  \n",
        "   Kaggle credentials are configured, and competition files (documents, queries, qrels) are downloaded via the Kaggle CLI.\n",
        "\n",
        "2. **Data Loading and Inspection**  \n",
        "   All downloaded JSONL/JSON files are read into Python lists or dictionaries, and basic stats (document and query counts) are displayed.\n",
        "\n",
        "3. **Evaluation Metric (P-Found)**  \n",
        "   A function `pfound_score` is defined to measure retrieval performance, demonstrating how to compute a score based on ranked predictions.\n",
        "\n",
        "4. **Text Preprocessing**  \n",
        "   Titles plus a portion of content are tokenized, stemmed, and filtered for stopwords. A dictionary of document frequencies (df) is built, and very low-frequency tokens are removed.\n",
        "\n",
        "5. **TF-IDF Construction**  \n",
        "   A sparse TF matrix is created for each document, IDF values are computed, and both are combined to form the final TF-IDF matrix.\n",
        "\n",
        "6. **Query Processing and Similarity Computation**  \n",
        "   Queries undergo the same tokenization and stemming. Their term frequencies are assembled into a sparse matrix, and cosine-like similarity scores are calculated by multiplying document TF-IDF by query term frequencies.\n",
        "\n",
        "7. **Submission File Creation**  \n",
        "   (Query, document) pairs and their computed scores are gathered into a dataframe and saved as a CSV file for submission."
      ],
      "metadata": {
        "id": "4fb8NdKZGbme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "Lc7PJ3DlILFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"kaggle.json\", \"r\") as f:\n",
        "    creds = json.load(f)"
      ],
      "metadata": {
        "id": "AuUSe7oSBIqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
        "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]"
      ],
      "metadata": {
        "id": "vEDf9iSmASFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_dir = Path(\"data\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-29T10:18:49.076806Z",
          "iopub.execute_input": "2024-04-29T10:18:49.078128Z",
          "iopub.status.idle": "2024-04-29T10:18:49.084807Z",
          "shell.execute_reply.started": "2024-04-29T10:18:49.078081Z",
          "shell.execute_reply": "2024-04-29T10:18:49.083298Z"
        },
        "trusted": true,
        "id": "IQC2DJ-ADOmv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "N_ZRwQK7CsIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m1SJFlxCVmb",
        "outputId": "6f20356d-b220-4d65-95c8-a690eb0147de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: kaggle [-h] [-v] [-W] {competitions,c,datasets,d,kernels,k,models,m,files,f,config} ...\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -v, --version         Print the Kaggle API version\n",
            "  -W, --no-warn         Disable out-of-date API version warning\n",
            "\n",
            "commands:\n",
            "  {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
            "                        Use one of:\n",
            "                        competitions {list, files, download, submit, submissions, leaderboard}\n",
            "                        datasets {list, files, download, create, version, init, metadata, status}\n",
            "                        kernels {list, files, init, push, pull, output, status}\n",
            "                        models {instances, get, list, init, create, delete, update}\n",
            "                        models instances {versions, get, files, init, create, delete, update}\n",
            "                        models instances versions {init, create, download, delete, files}\n",
            "                        config {view, set, unset}\n",
            "    competitions (c)    Commands related to Kaggle competitions\n",
            "    datasets (d)        Commands related to Kaggle datasets\n",
            "    kernels (k)         Commands related to Kaggle kernels\n",
            "    models (m)          Commands related to Kaggle models\n",
            "    files (f)           Commands related files\n",
            "    config              Configuration settings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-nup-2024-hw1 -f documents.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btjq7xiuCYyL",
        "outputId": "9472b828-6faf-4751-d8fa-6383544ae441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading documents.jsonl.zip to /content\n",
            " 99% 601M/605M [00:06<00:00, 90.9MB/s]\n",
            "100% 605M/605M [00:06<00:00, 102MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip documents.jsonl.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozgT_WfhDC5R",
        "outputId": "4bc6a949-e697-4988-9e0a-9c79b67a6d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  documents.jsonl.zip\n",
            "  inflating: documents.jsonl         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "with open('documents.jsonl') as fp:\n",
        "    for line in tqdm(fp, total=367840):\n",
        "        docs.append(json.loads(line))\n",
        "\n",
        "print(f'Number of documents to search in: {len(docs)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:18:54.009266Z",
          "iopub.execute_input": "2024-04-29T10:18:54.009769Z",
          "iopub.status.idle": "2024-04-29T10:19:28.527326Z",
          "shell.execute_reply.started": "2024-04-29T10:18:54.009733Z",
          "shell.execute_reply": "2024-04-29T10:19:28.526142Z"
        },
        "trusted": true,
        "id": "OzuBopprDOmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f206c109-c712-4b21-9565-43f4c47febb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367840/367840 [00:14<00:00, 25239.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents to search in: 367840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:19:40.086274Z",
          "iopub.execute_input": "2024-04-29T10:19:40.086772Z",
          "iopub.status.idle": "2024-04-29T10:19:40.096397Z",
          "shell.execute_reply.started": "2024-04-29T10:19:40.086739Z",
          "shell.execute_reply": "2024-04-29T10:19:40.094982Z"
        },
        "trusted": true,
        "id": "1mx8aPOODOmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8ded31-e325-4027-b73c-b5b377e305c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'e1a4606fc85ca4c34cc1fc9dc3a85264',\n",
              " 'url': 'https://www.reuters.com/article/us-puertorico-hurricane-lawsuit/judge-orders-further-extension-of-aid-to-puerto-rico-storm-evacuees-idUKKBN1KM4G6?edition-redirect=uk',\n",
              " 'title': 'Judge orders further extension of aid to Puerto Rico storm evacuees',\n",
              " 'contents': 'Judge orders further extension of aid to Puerto Rico storm evacuees\\nBy Nate Raymond3 Min Read\\nWORCESTER, Mass. (Reuters) - A federal judge on Wednesday extended until Aug. 31 an order preventing the eviction of hundreds of Puerto Rican families who fled the hurricane-ravaged island in 2017 and have been living in hotels and motels across the United States.\\nFILE PHOTO: Buildings damaged by Hurricane Maria are seen in Lares, Puerto Rico, October 6, 2017. REUTERS/Lucas Jackson/File Photo\\nU.S. District Judge Timothy Hillman in Worcester, Massachusetts, issued the order after hearing arguments over whether he should issue a longer-term injunction barring the federal government from cutting off housing assistance to people who were forced to leave their homes because of Hurricane Maria.\\nThe Federal Emergency Management Agency (FEMA) had planned to end the assistance program on June 30. Hillman’s decision on Wednesday extended a previously-imposed temporary restraining order that allowed the families to remain in hotels until checkout time on Aug. 7.\\nHillman extended the order to allow the government time to respond to new arguments raised by lawyers representing evacuees in a proposed class action challenging FEMA’s actions.\\n“It’s going to take us time sort through this,” he said.\\nHurricane Maria hit Puerto Rico on Sept. 20 with winds close to 150 miles per hour (240 kph), causing an estimated $90 billion in damage to the already economically struggling U.S. territory.\\nAccording to FEMA, 1,040 families displaced by Maria are currently receiving aid under a program that pays for hotel lodging. In total, the program has since its launch helped 7,032 families displaced by Maria, FEMA said.\\nCritics have said the federal government responded poorly to the disaster and provided inadequate aid. They contend that President Donald Trump’s administration viewed Puerto Ricans as second-class citizens, a claim it denies.\\nFour Puerto Ricans are pursuing the lawsuit, which was filed in June and contends that FEMA’s actions violate their due process rights under the U.S. Constitution.\\nLawyers for the displaced Puerto Ricans argued in court that FEMA is legally obligated to continue to provide assistance to the evacuees, who they contend face potential homelessness if the program is prematurely ended without providing other assistance.\\n“They have no place to go back to, and what they’re seeking is assistance from the agency that already promised to give it to them,” said Natasha Bannan, an attorney with the advocacy organization LatinoJustice PRLDEF.\\nBut Danielle Wolfson Young, a lawyer with the U.S. Justice Department representing FEMA, argued that the families had no right to continued assistance.\\n“FEMA has the discretion to implement and also to determine when to end the program,” she said.\\nReporting by Nate Raymond in; Worcester; Editing by Bill BerkrotOur Standards: The Thomson Reuters Trust Principles.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-nup-2024-hw1 -f queries_train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PktLdYC1DcIH",
        "outputId": "3d9b42b6-5aff-4d02-b248-7e68378958e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading queries_train.json to /content\n",
            "\r  0% 0.00/32.5k [00:00<?, ?B/s]\n",
            "\r100% 32.5k/32.5k [00:00<00:00, 30.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip queries_train.json.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CWMuNbbDedm",
        "outputId": "0771dfe2-21cc-4f98-da47-54dc98a4da1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open queries_train.json.zip, queries_train.json.zip.zip or queries_train.json.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('queries_train.json') as fp:\n",
        "    queries = json.load(fp)\n",
        "\n",
        "print(f'Number of train queries: {len(queries)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:19:43.141386Z",
          "iopub.execute_input": "2024-04-29T10:19:43.141906Z",
          "iopub.status.idle": "2024-04-29T10:19:43.156299Z",
          "shell.execute_reply.started": "2024-04-29T10:19:43.141868Z",
          "shell.execute_reply": "2024-04-29T10:19:43.154562Z"
        },
        "trusted": true,
        "id": "TF9a6bnxDOmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fe7608-16f4-4f9a-a82a-a383efc95d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train queries: 28\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "queries[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:19:46.063415Z",
          "iopub.execute_input": "2024-04-29T10:19:46.063851Z",
          "iopub.status.idle": "2024-04-29T10:19:46.072587Z",
          "shell.execute_reply.started": "2024-04-29T10:19:46.063819Z",
          "shell.execute_reply": "2024-04-29T10:19:46.071218Z"
        },
        "trusted": true,
        "id": "2aTdLZYhDOmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786b4d87-2153-4249-e41d-4529a7577f19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_id': 'history-1',\n",
              " 'query': 'Would the United Kingdom have been ready for WWII without the time gained through Appeasement?',\n",
              " 'domain': 'history',\n",
              " 'guidelines': \"Many argue Britain's army was depleted in the early 1930s and stretched across the globe. UK defence spending had fallen significantly during the 1920s, from over £700 million in 1919 to 100 million in 1931.\\n\\nBetween 1934 and 1939, the UK launched a substantial programme of re-arming, recognising that war with Hitler was becoming increasingly likely. Although Appeasement was also motivated by Chamberlain's desire to end war, some argue this meant that the UK was more prepared in 1939 when war eventually broke out.  \\n\\nDespite these efforts, Germany was still better prepared for war under Hilter's single-minded preparation since he came to power in 1933. However, without Appeasement, the differential might have been much worse.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-nup-2024-hw1 -f qrels_train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xij4lPI3DvBN",
        "outputId": "7df472f0-f1ff-4b34-ac87-3fadd067d0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading qrels_train.json to /content\n",
            "100% 449k/449k [00:00<00:00, 1.33MB/s]\n",
            "100% 449k/449k [00:00<00:00, 1.33MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip qrels_train.json.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PeGLsM5D1Te",
        "outputId": "436ee3bf-ee49-4510-d6a5-ed04515744aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open qrels_train.json.zip, qrels_train.json.zip.zip or qrels_train.json.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('qrels_train.json') as fp:\n",
        "    qrels = json.load(fp)\n",
        "\n",
        "print(f'Number of assessed query/document pairs: {len(qrels)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:19:59.629624Z",
          "iopub.execute_input": "2024-04-29T10:19:59.630051Z",
          "iopub.status.idle": "2024-04-29T10:19:59.657394Z",
          "shell.execute_reply.started": "2024-04-29T10:19:59.630022Z",
          "shell.execute_reply": "2024-04-29T10:19:59.65578Z"
        },
        "trusted": true,
        "id": "TvIrpqmnDOmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901b4b1a-e13f-47c5-f4d2-a0d5baea570e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of assessed query/document pairs: 4216\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Example of single assesed pair:')\n",
        "qrels[0:2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:20:02.978462Z",
          "iopub.execute_input": "2024-04-29T10:20:02.978937Z",
          "iopub.status.idle": "2024-04-29T10:20:02.987937Z",
          "shell.execute_reply.started": "2024-04-29T10:20:02.978903Z",
          "shell.execute_reply": "2024-04-29T10:20:02.986628Z"
        },
        "trusted": true,
        "id": "oZLbUc3iDOmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94eeef45-97ab-4dd6-9c45-b727e1f7cf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of single assesed pair:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query_id': 'history-20',\n",
              "  'doc_id': '00aa648a657bdf73369bcb093030cc41',\n",
              "  'relevance': 0,\n",
              "  'iteration': 'Q0'},\n",
              " {'query_id': 'history-20',\n",
              "  'doc_id': '0260670b7616127813246a8c76c6d223',\n",
              "  'relevance': 0,\n",
              "  'iteration': 'Q0'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def pfound_score(y_true: 'npt.NDArray[np.int_]', y_score: 'npt.NDArray[np.float_]', pbreak: float = .15) -> float:\n",
        "    assert y_true.shape == y_score.shape\n",
        "\n",
        "    indices = np.argsort(y_score)[::-1]\n",
        "\n",
        "    y_max = max(y_true)\n",
        "\n",
        "    pfound, plook = 0., 1.\n",
        "\n",
        "    for rank, i in enumerate(indices):\n",
        "        r = (2. ** y_true[i] - 1.) / (2. ** y_max)\n",
        "\n",
        "        pfound += r * plook * pbreak ** rank\n",
        "\n",
        "        plook *= 1. - r\n",
        "\n",
        "    return pfound\n",
        "\n",
        "\n",
        "def pfound(qrels_list: list[dict[str: str | int]],\n",
        "           y_pred: list[dict[str: str | float]],\n",
        "           pbreak: float = 0.15\n",
        "          ) -> float:\n",
        "    assert 0 < pbreak < 1\n",
        "    zero_score_qrel = {'score': 0.0, 'relevance': 0.0}\n",
        "\n",
        "    queries = set(qrel['query_id'] for qrel in qrels_list)\n",
        "    p_found_list = []\n",
        "    for cur_query in queries:\n",
        "        cur_y_pred_dicts = [doc_ranked for doc_ranked in y_pred\n",
        "                            if doc_ranked['query_id'] == cur_query]\n",
        "        y = {qrel['doc_id']: qrel for qrel in qrels_list if qrel['query_id'] == cur_query}\n",
        "        cur_y_pred = np.empty(len(cur_y_pred_dicts))\n",
        "        cur_y_true = np.empty(len(cur_y_pred_dicts))\n",
        "        for n, y_pred_dict in enumerate(cur_y_pred_dicts):\n",
        "            cur_y_pred[n] = y_pred_dict['score']\n",
        "            cur_y_true[n] = y.get(y_pred_dict['doc_id'], zero_score_qrel)['relevance']\n",
        "\n",
        "        cur_pfound = pfound_score(np.array(cur_y_true), np.array(cur_y_pred))\n",
        "        p_found_list.append(cur_pfound)\n",
        "    return float(np.mean(p_found_list))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T13:46:54.722685Z",
          "iopub.execute_input": "2024-04-04T13:46:54.723211Z",
          "iopub.status.idle": "2024-04-04T13:46:54.733535Z",
          "shell.execute_reply.started": "2024-04-04T13:46:54.723174Z",
          "shell.execute_reply": "2024-04-04T13:46:54.732388Z"
        },
        "trusted": true,
        "id": "3JSCC8cBDOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating random predictions\n",
        "\n",
        "For a pair of document and query we return just a random number. This solution can be treated as the lowest possible bound on the quality of our retrieval system."
      ],
      "metadata": {
        "id": "pB8LEnJJDOmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def random_similarity(doc: dict[str: str], query: dict[str: str]) -> float:\n",
        "#    doc_text = doc['contents']\n",
        "#    doc_title = doc['title']\n",
        "#    query_text = query['query']\n",
        "#    query_guidelines = query['guidelines']\n",
        "#    return random.random()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T13:46:55.270667Z",
          "iopub.execute_input": "2024-04-04T13:46:55.271057Z",
          "iopub.status.idle": "2024-04-04T13:46:55.277072Z",
          "shell.execute_reply.started": "2024-04-04T13:46:55.271028Z",
          "shell.execute_reply": "2024-04-04T13:46:55.275215Z"
        },
        "trusted": true,
        "id": "Nhjvbp-XDOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating predictions"
      ],
      "metadata": {
        "id": "U5TBjfz-DOmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preds = []\n",
        "#\n",
        "#for q in tqdm(queries):\n",
        "#    for d in docs:\n",
        "#        pred_sim = random_similarity(d, q)\n",
        "#        preds.append({\n",
        "#            'doc_id': d['id'],\n",
        "#            'query_id': q['query_id'],\n",
        "#            'score': pred_sim\n",
        "#        })"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T13:46:56.174916Z",
          "iopub.execute_input": "2024-04-04T13:46:56.175698Z",
          "iopub.status.idle": "2024-04-04T13:47:07.660865Z",
          "shell.execute_reply.started": "2024-04-04T13:46:56.175671Z",
          "shell.execute_reply": "2024-04-04T13:47:07.659939Z"
        },
        "trusted": true,
        "id": "Nr1c-EziDOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scorring the solution"
      ],
      "metadata": {
        "id": "XKPLcOa2DOmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pfound(qrels, preds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T13:52:43.072985Z",
          "iopub.execute_input": "2024-04-04T13:52:43.073369Z",
          "iopub.status.idle": "2024-04-04T13:53:20.576461Z",
          "shell.execute_reply.started": "2024-04-04T13:52:43.073345Z",
          "shell.execute_reply": "2024-04-04T13:53:20.575608Z"
        },
        "trusted": true,
        "id": "oaX_cEPIDOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.sparse import csr_matrix, coo_matrix\n",
        "from math import log"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:24:50.069905Z",
          "iopub.execute_input": "2024-04-29T10:24:50.070403Z",
          "iopub.status.idle": "2024-04-29T10:24:50.078123Z",
          "shell.execute_reply.started": "2024-04-29T10:24:50.070369Z",
          "shell.execute_reply": "2024-04-29T10:24:50.076488Z"
        },
        "trusted": true,
        "id": "7mtiMydDDOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:24:53.698554Z",
          "iopub.execute_input": "2024-04-29T10:24:53.699272Z",
          "iopub.status.idle": "2024-04-29T10:24:53.705542Z",
          "shell.execute_reply.started": "2024-04-29T10:24:53.699237Z",
          "shell.execute_reply": "2024-04-29T10:24:53.703972Z"
        },
        "trusted": true,
        "id": "0W5EQeXODOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_set = set(stopwords.words('english'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:24:57.022734Z",
          "iopub.execute_input": "2024-04-29T10:24:57.023117Z",
          "iopub.status.idle": "2024-04-29T10:24:57.032063Z",
          "shell.execute_reply.started": "2024-04-29T10:24:57.023089Z",
          "shell.execute_reply": "2024-04-29T10:24:57.030468Z"
        },
        "trusted": true,
        "id": "aEX0yZuBDOmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4c1384-2d2d-4a0a-ef12-be2d5813d9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#let's tokenize only the titles, not full text\n",
        "df = defaultdict(int)\n",
        "\n",
        "for doc in tqdm(docs):\n",
        "    title_len = len(doc['title'])\n",
        "    content_titles = doc['contents'][:title_len+200]\n",
        "    tokens = [stemmer.stem(tok) for tok in tokenizer.tokenize(content_titles)]\n",
        "\n",
        "    unique_tokens = set(tokens)\n",
        "    for tok in unique_tokens:\n",
        "        df[tok] += 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T10:54:07.392281Z",
          "iopub.execute_input": "2024-04-29T10:54:07.392742Z",
          "iopub.status.idle": "2024-04-29T10:59:31.988482Z",
          "shell.execute_reply.started": "2024-04-29T10:54:07.392701Z",
          "shell.execute_reply": "2024-04-29T10:59:31.986957Z"
        },
        "trusted": true,
        "id": "lINJOKzSDOmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3408ff-240d-4fa3-f6dc-e5ac17b646d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367840/367840 [03:09<00:00, 1942.27it/s]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#token indexing\n",
        "tok_indexed = {key: i for i, key in enumerate(df.keys())}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T12:06:08.878917Z",
          "iopub.execute_input": "2024-04-29T12:06:08.879355Z",
          "iopub.status.idle": "2024-04-29T12:06:09.006199Z",
          "shell.execute_reply.started": "2024-04-29T12:06:08.879323Z",
          "shell.execute_reply": "2024-04-29T12:06:09.002172Z"
        },
        "trusted": true,
        "id": "W3_E401KDOmx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "single_words = [key for key, value in df.items() if value == 1][:10]\n",
        "single_words"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T12:34:04.954933Z",
          "iopub.execute_input": "2024-04-29T12:34:04.955379Z",
          "iopub.status.idle": "2024-04-29T12:34:04.997199Z",
          "shell.execute_reply.started": "2024-04-29T12:34:04.955345Z",
          "shell.execute_reply": "2024-04-29T12:34:04.995658Z"
        },
        "trusted": true,
        "id": "cClW5hZuDOmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6380266-8a22-42c0-fc60-3b1b3a29864f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['riphyakforb',\n",
              " 'yurij',\n",
              " 'burstcoin',\n",
              " 'tanai',\n",
              " 'heijin',\n",
              " 'renshaw9',\n",
              " 'decentralist',\n",
              " 'universam',\n",
              " 'perpetua',\n",
              " 'scripturam']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#above we can see that we also have a lot of values that occur only once. let's filter them and stop words\n",
        "df_filtered = {k: v for k, v in df.items() if v > 1 and k not in stop_set}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T12:06:12.566516Z",
          "iopub.execute_input": "2024-04-29T12:06:12.566941Z",
          "iopub.status.idle": "2024-04-29T12:06:12.622598Z",
          "shell.execute_reply.started": "2024-04-29T12:06:12.566909Z",
          "shell.execute_reply": "2024-04-29T12:06:12.621259Z"
        },
        "trusted": true,
        "id": "r3lL1S7rDOmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tok = {key: i for i, key in enumerate(df_filtered.keys())}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T12:06:14.76646Z",
          "iopub.execute_input": "2024-04-29T12:06:14.766892Z",
          "iopub.status.idle": "2024-04-29T12:06:14.818999Z",
          "shell.execute_reply.started": "2024-04-29T12:06:14.76686Z",
          "shell.execute_reply": "2024-04-29T12:06:14.817224Z"
        },
        "trusted": true,
        "id": "FN72Zlh4DOmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rows, cols, tf_values, idf_values = [], [], [], []\n",
        "\n",
        "num_docs = len(docs)\n",
        "num_tokens = len(filtered_tok)\n",
        "\n",
        "for i, doc in tqdm(enumerate(docs)):\n",
        "    title_len = len(doc['title'])\n",
        "    content_titles = doc['contents'][:title_len+200]\n",
        "    tokens = [stemmer.stem(tok) for tok in tokenizer.tokenize(content_titles)]\n",
        "    token_counts = len(tokens)\n",
        "    unique_tokens = Counter(tokens)\n",
        "\n",
        "    for tok, count in unique_tokens.items():\n",
        "        if tok not in filtered_tok:\n",
        "            continue\n",
        "        col = filtered_tok[tok]\n",
        "        row = i\n",
        "        tf_item = count / token_counts\n",
        "        idf_item = log(num_docs / df_filtered[tok])\n",
        "\n",
        "        rows.append(row)\n",
        "        cols.append(col)\n",
        "        tf_values.append(tf_item)\n",
        "        idf_values.append(idf_item)\n",
        "\n",
        "tf_matrix = coo_matrix((tf_values, (rows, cols)), shape=(num_docs, num_tokens))\n",
        "idf_matrix = coo_matrix((idf_values, (rows, cols)), shape=(num_docs, num_tokens))\n",
        "\n",
        "tf_idf_matrix = tf_matrix.multiply(idf_matrix) #completed TF-IDF matrix"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:25:49.133397Z",
          "iopub.execute_input": "2024-04-29T13:25:49.136186Z",
          "iopub.status.idle": "2024-04-29T13:31:43.956315Z",
          "shell.execute_reply.started": "2024-04-29T13:25:49.136146Z",
          "shell.execute_reply": "2024-04-29T13:31:43.954773Z"
        },
        "trusted": true,
        "id": "rjsvf_JFDOmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd671902-ee07-447a-87b8-fd0d18603043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [03:38, 1685.05it/s]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf_matrix.shape, idf_matrix.shape, tf_idf_matrix.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:33:00.521849Z",
          "iopub.execute_input": "2024-04-29T13:33:00.522284Z",
          "iopub.status.idle": "2024-04-29T13:33:00.529213Z",
          "shell.execute_reply.started": "2024-04-29T13:33:00.522251Z",
          "shell.execute_reply": "2024-04-29T13:33:00.527981Z"
        },
        "trusted": true,
        "id": "-KR5B1ahDOmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d63cdc0-d70b-48df-a2ab-a49cb7a7bb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(367840, 91819) (367840, 91819) (367840, 91819)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-nup-2024-hw1 -f queries_test.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmxKyIfRGTLz",
        "outputId": "145876d2-2689-47c9-de9e-85cb29719674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading queries_test.json to /content\n",
            "\r  0% 0.00/12.7k [00:00<?, ?B/s]\n",
            "\r100% 12.7k/12.7k [00:00<00:00, 19.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip queries_test.json.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDCYdjoKGXS-",
        "outputId": "28ab0738-a6b3-484e-b2eb-91c25b2182f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open queries_test.json.zip, queries_test.json.zip.zip or queries_test.json.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('queries_test.json') as fp:\n",
        "    qs_test = json.load(fp)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:42:51.219262Z",
          "iopub.execute_input": "2024-04-29T13:42:51.219783Z",
          "iopub.status.idle": "2024-04-29T13:42:51.226038Z",
          "shell.execute_reply.started": "2024-04-29T13:42:51.219746Z",
          "shell.execute_reply": "2024-04-29T13:42:51.224478Z"
        },
        "trusted": true,
        "id": "j3FDj1SxDOmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "query_tf, query_rows, query_cols = [], [], []\n",
        "\n",
        "#request processing\n",
        "for i, query in tqdm(enumerate(qs_test)):\n",
        "    tokens = [stemmer.stem(tok) for tok in tokenizer.tokenize(query['query'])]\n",
        "    unique_tokens = Counter(tokens)\n",
        "\n",
        "    for tok, count in unique_tokens.items():\n",
        "        if tok not in filtered_tok:\n",
        "            continue\n",
        "        col = filtered_tok[tok]\n",
        "        row = i\n",
        "        tf_item = count\n",
        "        query_rows.append(row)\n",
        "        query_cols.append(col)\n",
        "        query_tf.append(tf_item)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:42:54.664013Z",
          "iopub.execute_input": "2024-04-29T13:42:54.666644Z",
          "iopub.status.idle": "2024-04-29T13:42:54.685386Z",
          "shell.execute_reply.started": "2024-04-29T13:42:54.6666Z",
          "shell.execute_reply": "2024-04-29T13:42:54.684016Z"
        },
        "trusted": true,
        "id": "jHwe90zYDOmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010ade74-135b-44b7-c13d-4cd472d66ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14it [00:00, 4056.95it/s]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#create a frequency matrix\n",
        "query_tf_matrix = csr_matrix((query_tf, (query_rows, query_cols)), shape=(len(qs_test), num_tokens))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:50:16.04762Z",
          "iopub.execute_input": "2024-04-29T13:50:16.048152Z",
          "iopub.status.idle": "2024-04-29T13:50:16.056058Z",
          "shell.execute_reply.started": "2024-04-29T13:50:16.048115Z",
          "shell.execute_reply": "2024-04-29T13:50:16.054781Z"
        },
        "trusted": true,
        "id": "YfZ98rHUDOmy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_score = tf_idf_matrix.dot(query_tf_matrix.transpose())\n",
        "similarity_score.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:43:04.061724Z",
          "iopub.execute_input": "2024-04-29T13:43:04.062212Z",
          "iopub.status.idle": "2024-04-29T13:43:04.129074Z",
          "shell.execute_reply.started": "2024-04-29T13:43:04.062176Z",
          "shell.execute_reply": "2024-04-29T13:43:04.12757Z"
        },
        "trusted": true,
        "id": "6GvhxdgADOmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c28cd8-1b5e-4015-fb8b-70eca085c285"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(367840, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "random_submission_items = []\n",
        "\n",
        "for i, q in enumerate(qs_test):\n",
        "    print(f'Generating socres for query {q[\"query_id\"]}')\n",
        "    for j, d in tqdm(enumerate(docs)):\n",
        "        q_id = q['query_id']\n",
        "        doc_id = d['id']\n",
        "        random_submission_items.append({\n",
        "            'id': f'{q_id}_{doc_id}',\n",
        "            'query_id': q['query_id'],\n",
        "            'doc_id': d['id'],\n",
        "            'score': similarity_score[j, i]\n",
        "        })"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:50:31.08127Z",
          "iopub.execute_input": "2024-04-29T13:50:31.08167Z",
          "iopub.status.idle": "2024-04-29T13:53:35.218406Z",
          "shell.execute_reply.started": "2024-04-29T13:50:31.081639Z",
          "shell.execute_reply": "2024-04-29T13:53:35.216705Z"
        },
        "trusted": true,
        "id": "5g3qw2ksDOmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0132ef3-a35e-4d8a-a7d0-50b7bd376345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:13, 27442.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:11, 33142.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:11, 33406.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:10, 35720.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:09, 37597.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:10, 33757.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:11, 30798.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:11, 33302.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:09, 37702.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:10, 34140.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:11, 33266.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:11, 31048.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:09, 37353.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating socres for query economics-23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "367840it [00:10, 35155.98it/s]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(random_submission_items)\n",
        "df.set_index('id', inplace=True)\n",
        "df.to_csv('submission.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T13:58:31.007566Z",
          "iopub.execute_input": "2024-04-29T13:58:31.008111Z",
          "iopub.status.idle": "2024-04-29T13:59:12.476274Z",
          "shell.execute_reply.started": "2024-04-29T13:58:31.008075Z",
          "shell.execute_reply": "2024-04-29T13:59:12.474808Z"
        },
        "trusted": true,
        "id": "E9aIZg09DOmy"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}